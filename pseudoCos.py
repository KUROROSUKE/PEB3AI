import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

element_weights = {
    "H": 0.16666,
    "C": 0.25,
    "O": 0.25
    # ä»–ã®å…ƒç´ ã¯ 1.0 ã®ã¾ã¾
}

# ğŸ¯ **ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€**
with open("compound/obf_extended_min.json", "r", encoding="utf-8") as file:
    data = json.load(file)

# ğŸ¯ **å…ƒç´ ãƒªã‚¹ãƒˆã‚’å–å¾—**
all_elements = set()
for material in data["material"]:
    all_elements.update(material["d"].keys())
all_elements = sorted(all_elements)  # ä¸€è²«ã—ãŸé †åºã§ã‚½ãƒ¼ãƒˆ

# ğŸ¯ **ç‰©è³ªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–**
def convert_to_vector(composition):
    return np.array([
        composition.get(el, 0) * element_weights.get(el, 1.0)
        for el in all_elements
    ])

vectors = np.array([convert_to_vector(m["d"]) for m in data["material"]])

# ğŸ¯ **ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—**
similarity_matrix = cosine_similarity(vectors)

# ğŸ¯ **æœ€ã‚‚è¿‘ã„ç‰©è³ªã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆé–¾å€¤ 0.5 ä»¥ä¸‹ãªã‚‰ g ã‚’ nullï¼‰**
THRESHOLD = 0.5

for i, material in enumerate(data["material"]):
    similarities = similarity_matrix[i]
    sorted_indices = np.argsort(similarities)[::-1]  # é¡ä¼¼åº¦ãŒé«˜ã„é †
    closest_material = None

    for j in sorted_indices:
        if j != i:  # **è‡ªåˆ†è‡ªèº«ã‚’é™¤ã**
            if similarities[j] > THRESHOLD:
                closest_material = data["material"][j]["f"]
            break  # **æœ€ã‚‚è¿‘ã„ç‰©è³ªã‚’ 1 ã¤ã ã‘å–å¾—**

    material["g"] = closest_material  # **é–¾å€¤ä»¥ä¸‹ãªã‚‰ `null` ã«è¨­å®š**

# ğŸ¯ **æ–°ã—ã„ JSON ã‚’ä¿å­˜**
output_path = "compound/obs_standard_with_g_threshold.json"
with open(output_path, "w", encoding="utf-8") as file:
    json.dump(data, file, ensure_ascii=False, indent=4)

print(f"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚æ–°ã—ã„ JSON ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
